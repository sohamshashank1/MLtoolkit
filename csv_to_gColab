##Load Google Drive CSV into Pandas DataFrame for Google Colaboratory ( my reference guide) 
```
import tensorflow as tf
tf.test.gpu_device_name()

!pip install -U -q PyDrive
 
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
 
# 1. Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

file_list = drive.ListFile({'q': "'<FOLDER ID>' in parents and trashed=false"}).GetList()
for file1 in file_list:
  print('title: %s, id: %s' % (file1['title'], file1['id']))
  
  ```
  
 ## output would be 
title: train.csv, id: <TRAIN_FILE_ID>
title: test.csv, id: <TEST_FILE_ID>

```
train_downloaded = drive.CreateFile({'id': '<TRAIN_FILE_ID>'})
train_downloaded.GetContentFile('train.csv')
test_downloaded = drive.CreateFile({'id': '<TEST_FILE_ID>'})
test_downloaded.GetContentFile('test.csv')  
```
##Now the files get pulled into Google Colab. GetContentFile saves the files in the local environment and sets the names of the files.
```
import pandas as pd
import numpy as np
df_train = pd.read_csv('train.csv')
df_train
```
